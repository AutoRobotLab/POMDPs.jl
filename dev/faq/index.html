<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Frequently Asked Questions (FAQ) · POMDPs.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="POMDPs.jl logo"/></a><h1>POMDPs.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><span class="toctext">Basics</span><ul><li><a class="toctext" href="../">POMDPs.jl</a></li><li><a class="toctext" href="../install/">Installation</a></li><li><a class="toctext" href="../get_started/">Getting Started</a></li><li><a class="toctext" href="../concepts/">Concepts and Architecture</a></li></ul></li><li><span class="toctext">Defining POMDP Models</span><ul><li><a class="toctext" href="../def_pomdp/">Defining POMDPs</a></li><li><a class="toctext" href="../explicit/">Explicit POMDP Interface</a></li><li><a class="toctext" href="../generative/">Generative POMDP Interface</a></li><li><a class="toctext" href="../requirements/">Interface Requirements for Problems</a></li><li><a class="toctext" href="../interfaces/">Spaces and Distributions</a></li></ul></li><li><span class="toctext">Writing Solvers and Updaters</span><ul><li><a class="toctext" href="../def_solver/">Defining a Solver</a></li><li><a class="toctext" href="../specifying_requirements/">Specifying Requirements</a></li><li><a class="toctext" href="../def_updater/">Defining a Belief Updater</a></li></ul></li><li><span class="toctext">Analyzing Results</span><ul><li><a class="toctext" href="../simulation/">Simulation Standard</a></li><li><a class="toctext" href="../run_simulation/">Running Simulations</a></li><li><a class="toctext" href="../policy_interaction/">Interacting with Policies</a></li></ul></li><li class="current"><a class="toctext" href>Frequently Asked Questions (FAQ)</a><ul class="internal"><li><a class="toctext" href="#How-do-I-save-my-policies?-1">How do I save my policies?</a></li><li><a class="toctext" href="#Why-isn&#39;t-the-solver-working?-1">Why isn&#39;t the solver working?</a></li><li><a class="toctext" href="#Why-do-I-need-to-put-type-assertions-pomdp::POMDP-into-the-function-signature?-1">Why do I need to put type assertions pomdp::POMDP into the function signature?</a></li><li><a class="toctext" href="#Why-are-all-the-solvers-in-separate-modules?-1">Why are all the solvers in separate modules?</a></li><li><a class="toctext" href="#How-can-I-implement-terminal-actions?-1">How can I implement terminal actions?</a></li><li><a class="toctext" href="#Why-are-there-two-versions-of-reward?-1">Why are there two versions of <code>reward</code>?</a></li><li><a class="toctext" href="#How-do-I-implement-reward(m,-s,-a)-if-the-reward-depends-on-the-next-state?-1">How do I implement <code>reward(m, s, a)</code> if the reward depends on the next state?</a></li></ul></li><li><a class="toctext" href="../api/">API Documentation</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Frequently Asked Questions (FAQ)</a></li></ul><a class="edit-page" href="https://github.com/JuliaPOMDP/POMDPs.jl/blob/master/docs/src/faq.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Frequently Asked Questions (FAQ)</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Frequently-Asked-Questions-(FAQ)-1" href="#Frequently-Asked-Questions-(FAQ)-1">Frequently Asked Questions (FAQ)</a></h1><h2><a class="nav-anchor" id="How-do-I-save-my-policies?-1" href="#How-do-I-save-my-policies?-1">How do I save my policies?</a></h2><p>We recommend using <a href="https://github.com/JuliaIO/JLD.jl">JLD</a> to save the whole policy object. This is a simple and fairly efficient way to save Julia objects. JLD uses the HDF5 format underneath. To save a computed policy, run:</p><pre><code class="language-julia">using JLD
save(&quot;my_policy.jld&quot;, &quot;policy&quot;, policy)</code></pre><h2><a class="nav-anchor" id="Why-isn&#39;t-the-solver-working?-1" href="#Why-isn&#39;t-the-solver-working?-1">Why isn&#39;t the solver working?</a></h2><p>There could be a number of things that are going wrong. Remeber, POMDPs can be failry hard to work with, but don&#39;t panic.  If you have a discrete POMDP or MDP and you&#39;re using a solver that requires the explicit transition probabilities (you&#39;ve implemented a <code>pdf</code> function), the first thing to try is make sure that your probability masses sum up to unity.  We&#39;ve provide some tools in POMDPToolbox that can check this for you. If you have a POMDP called pomdp, you can run the checks by doing the following:</p><pre><code class="language-julia">using POMDPTesting
probability_check(pomdp) # checks that both observation and transition functions give probs that sum to unity
obs_prob_consistency_check(pomdp) # checks the observation probabilities
trans_prob_consistency_check(pomdp) # check the transition probabilities</code></pre><p>If these throw an error, you may need to fix your <code>transition</code> or <code>observation</code> functions. </p><h2><a class="nav-anchor" id="Why-do-I-need-to-put-type-assertions-pomdp::POMDP-into-the-function-signature?-1" href="#Why-do-I-need-to-put-type-assertions-pomdp::POMDP-into-the-function-signature?-1">Why do I need to put type assertions pomdp::POMDP into the function signature?</a></h2><p>Specifying the type in your function signature allows Julia to call the appropriate function when your custom type is passed into it. For example if a POMDPs.jl solver calls <code>states</code> on the POMDP that you passed into it, the correct <code>states</code> function will only get dispatched if you specified that the <code>states</code> function you wrote works with your POMDP type. Because Julia supports multiple-dispatch, these type assertion are a way for doing object-oriented programming in Julia.</p><h2><a class="nav-anchor" id="Why-are-all-the-solvers-in-separate-modules?-1" href="#Why-are-all-the-solvers-in-separate-modules?-1">Why are all the solvers in separate modules?</a></h2><p>We did not put all the solvers and support tools into POMDPs.jl, because we wanted POMDPs.jl to be a lightweight interface package. This has a number of advantages. The first is that if a user only wants to use a few solvers from the JuliaPOMDP organization, they do not have to install all the other solvers and their dependencies. The second advantage is that people who are not directly part of the JuliaPOMDP organization can write their own solvers without going into the source code of other solvers. This makes the framework easier to adopt and to extend.</p><h2><a class="nav-anchor" id="How-can-I-implement-terminal-actions?-1" href="#How-can-I-implement-terminal-actions?-1">How can I implement terminal actions?</a></h2><p>Terminal actions are actions that cause the MDP to terminate without generating a new state. POMDPs.jl handles terminal conditions via the <code>isterminal</code> function on states, and does not directly support terminal actions. If your MDP has a terminal action, you need to implement the model functions accordingly to generate a terminal state. In both generative and explicit cases, you will need some dummy state, say <code>spt</code>, that can be recognized as terminal by the <code>isterminal</code> function. One way to do this is to give <code>spt</code> a state value that is out of bounds (e.g. a vector of <code>NaN</code>s or <code>-1</code>s) and then check for that in <code>isterminal</code>, so that this does not clash with any conventional termination conditions on the state.</p><p>If a terminal action is taken, regardless of current state, the <code>transition</code> function should return a distribution with only one next state, <code>spt</code>, with probability 1.0. In the generative case, the new state generated should be <code>spt</code>. The <code>reward</code> function or the <code>r</code> in <code>generate_sr</code> can be set according to the cost of the terminal action.</p><h2><a class="nav-anchor" id="Why-are-there-two-versions-of-reward?-1" href="#Why-are-there-two-versions-of-reward?-1">Why are there two versions of <code>reward</code>?</a></h2><p>Both <code>reward(m, s, a)</code> and <code>reward(m, s, a, sp)</code> are included because of these two facts:</p><ol><li>Some non-native solvers use <code>reward(m, s, a)</code></li><li>Sometimes the reward depends on <code>s</code> and <code>sp</code>.</li></ol><p>It is reasonable to implement both as long as the (s, a) version is the expectation of the (s, a, s&#39;) version (see below).</p><h2><a class="nav-anchor" id="How-do-I-implement-reward(m,-s,-a)-if-the-reward-depends-on-the-next-state?-1" href="#How-do-I-implement-reward(m,-s,-a)-if-the-reward-depends-on-the-next-state?-1">How do I implement <code>reward(m, s, a)</code> if the reward depends on the next state?</a></h2><p>The solvers that require <code>reward(m, s, a)</code> only work on problems with finite state and action spaces. In this case, you can define <code>reward(m, s, a)</code> in terms of <code>reward(m, s, a, sp)</code> with the following code:</p><pre><code class="language-julia">const rdict = Dict{Tuple{S,A}, Float64}()

for s in states(m)
  for a in actions(m)
    r = 0.0
    td = transition(m, s, a) # transition distribution for s, a
    for sp in support(td)
      r += pdf(td, sp)*reward(m, s, a, sp)
    end
    rdict[(s, a)] = r
  end
end

POMDPs.reward(m, s, a) = rdict[(s, a)]</code></pre><footer><hr/><a class="previous" href="../policy_interaction/"><span class="direction">Previous</span><span class="title">Interacting with Policies</span></a><a class="next" href="../api/"><span class="direction">Next</span><span class="title">API Documentation</span></a></footer></article></body></html>
